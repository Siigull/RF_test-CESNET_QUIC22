{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8162/8162 [00:08<00:00, 1008.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:03<00:00, 49.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1247/1247 [00:08<00:00, 138.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from cesnet_datazoo.datasets import CESNET_QUIC22\n",
    "from cesnet_datazoo.config import DatasetConfig, AppSelection, ValidationApproach\n",
    "\n",
    "dataset = CESNET_QUIC22(\"~/datasets/CESNET-QUIC22/\", size=\"XS\")\n",
    "\n",
    "common_params = {\n",
    "    \"dataset\": dataset,\n",
    "    \"apps_selection\": AppSelection.ALL_KNOWN,\n",
    "    \"train_period_name\": \"W-2022-44\",\n",
    "    \"val_approach\": ValidationApproach.SPLIT_FROM_TRAIN,\n",
    "    \"train_val_split_fraction\": 0.2,\n",
    "    \"use_packet_histograms\": True,\n",
    "}\n",
    "dataset_config = DatasetConfig(**common_params)\n",
    "dataset.set_dataset_config_and_initialize(dataset_config)\n",
    "train_dataframe = dataset.get_train_df(flatten_ppi=True)\n",
    "val_dataframe = dataset.get_val_df(flatten_ppi=True)\n",
    "test_dataframe = dataset.get_test_df(flatten_ppi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from pyqlearning.q_learning import QLearning\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "X = train_dataframe.drop(columns=\"APP\").to_numpy()\n",
    "y = train_dataframe[\"APP\"].to_numpy()\n",
    "\n",
    "# X_test = test_dataframe.drop(columns=\"APP\").to_numpy()[:10000]\n",
    "# y_test = test_dataframe[\"APP\"].to_numpy()[:10000]\n",
    "\n",
    "# same amount of samples from all classes\n",
    "def create_balanced_test_data():\n",
    "    grouped = test_dataframe.groupby('APP')\n",
    "\n",
    "    X_arr = np.ndarray(shape = (10100, X.shape[1]))\n",
    "    y_arr = np.ndarray(shape = (10100,))\n",
    "\n",
    "    for index, i in enumerate(grouped):\n",
    "        X_temp = i[1].drop(columns=\"APP\").to_numpy()\n",
    "        y_temp = i[1][\"APP\"].to_numpy()\n",
    "\n",
    "        X_arr[index*100:(index*100)+100] = X_temp[:100]\n",
    "        y_arr[index*100:(index*100)+100] = y_temp[:100]\n",
    "\n",
    "    return (X_arr, y_arr)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class State_key:\n",
    "    percent_of_class : int  # 1e-2, 1e-1. 5e-1, 1, more than 1\n",
    "    predict_proba    : int  # 0-25, 25-50, 50-75, 75-100\n",
    "    correct_predict  : bool # True or False\n",
    "    percent_duration : int\n",
    "    # bytes_client     : int  # log3, 9 buckets\n",
    "    # bytes_server     : int  # log5, 7 buckets\n",
    "    duration         : int\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.percent_of_class + \\\n",
    "               self.predict_proba * 5 + \\\n",
    "               int(self.correct_predict) * 20 + \\\n",
    "               self.percent_duration * 40 + \\\n",
    "               self.duration * 320\n",
    "            #    self.bytes_client * 40 + \\\n",
    "            #    self.bytes_server * 360 + \\\n",
    "               \n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, State_key) or self.__hash__() != other.__hash__():\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        # return self.percent_of_class == other.percent_of_class and \\\n",
    "        #        self.predict_proba == other.predict_proba and \\\n",
    "        #        self.percent_used == other.percent_used and \\\n",
    "        #        self.correct_predict == other.correct_predict\n",
    "        \n",
    "class Q(QLearning):\n",
    "    def get_clf_prediction(self, index):\n",
    "\n",
    "        proba = self.clf.predict_proba(X[index].reshape(1, -1))[0]\n",
    "        hit = (self.clf.predict(X[index].reshape(1, -1)) == y[index])[0]\n",
    "\n",
    "        return (proba, hit)\n",
    "\n",
    "    def class_percent_into_discrete(self, percent):\n",
    "        for i in range(len(self.CLASS_PERCENT_VALUES)):\n",
    "            if percent < self.CLASS_PERCENT_VALUES[i]:\n",
    "                return i\n",
    "            \n",
    "        return len(self.CLASS_PERCENT_VALUES)\n",
    "    \n",
    "    def predict_proba_into_discrete(self, proba):\n",
    "        for i in range(len(self.PREDICT_PROBA_VALUES)):\n",
    "            if proba < self.PREDICT_PROBA_VALUES[i]:\n",
    "                return i\n",
    "            \n",
    "        return len(self.PREDICT_PROBA_VALUES)\n",
    "\n",
    "    def percent_used_into_discrete(self, percent):\n",
    "        for i, el in enumerate(self.PERCENT_USED_VALUES):\n",
    "            if percent < el:\n",
    "                return i\n",
    "            \n",
    "        return len(self.PERCENT_USED_VALUES)\n",
    "\n",
    "    def client_bytes_into_discrete(self, nbytes):\n",
    "        return int(np.clip(int(log(nbytes, 3)) - 5, 1, 9) - 1)\n",
    "    \n",
    "    def server_bytes_into_discrete(self, nbytes):\n",
    "        return int(np.clip(int(log(nbytes, 5)) - 4, 0, 7))\n",
    "\n",
    "    def duration_into_discrete(self, duration):\n",
    "        for i, el in enumerate(self.DURATION_VALUES):\n",
    "            if duration < el:\n",
    "                return i\n",
    "        \n",
    "        return len(self.DURATION_VALUES)\n",
    "\n",
    "    def percent_duration_into_discrete(self, duration):\n",
    "        for i, el in enumerate(self.DURATION_PERCENT_VALUES):\n",
    "            if duration < el:\n",
    "                return i\n",
    "        \n",
    "        return len(self.DURATION_PERCENT_VALUES)\n",
    "\n",
    "    def update_state(self, state_key, action_key):\n",
    "        # print(self.t, end = \" \")\n",
    "        # print(state_key, end = \" \")\n",
    "        # print(action_key)\n",
    "\n",
    "        sample_index = self.base_i + self.t + 1\n",
    "\n",
    "        next_class = y[sample_index]\n",
    "\n",
    "        if action_key == 1:\n",
    "            \n",
    "            self.class_amount[self.y_used[self.to_i - 1]] += 1\n",
    "            self.used += 1\n",
    "\n",
    "        class_percent = self.class_amount[next_class] / (self.used + self.base_samples)\n",
    "        \n",
    "        (proba, hit) = self.get_clf_prediction(sample_index)\n",
    "\n",
    "        res_index = np.where(self.clf.classes_ == next_class)\n",
    "        if len(res_index[0]):\n",
    "            proba = self.predict_proba_into_discrete(proba[res_index[0][0]])\n",
    "        else:\n",
    "            proba = 0\n",
    "\n",
    "        # client_bytes = self.client_bytes_into_discrete(X[sample_index][90])\n",
    "        # server_bytes = self.server_bytes_into_discrete(X[sample_index][91])\n",
    "\n",
    "        duration = self.duration_into_discrete(X[sample_index][94])\n",
    "        percent_duration = self.duration_amount[duration] / (self.used + self.base_samples)\n",
    "\n",
    "        return State_key(self.class_percent_into_discrete(class_percent), \n",
    "                         proba,\n",
    "                         hit,\n",
    "                         self.percent_duration_into_discrete(percent_duration),\n",
    "                         duration)\n",
    "\n",
    "    def initialize(self, cols, iters, already_used, nclasses):\n",
    "        self.q_count = defaultdict(int)\n",
    "\n",
    "        self.epsilon_greedy_rate = 0.9\n",
    "        self.alpha_value = 0.4\n",
    "        self.gamma_value = 0.9\n",
    "\n",
    "        self.clf = RandomForestClassifier(max_depth=10)\n",
    "\n",
    "        self.CLASS_PERCENT_VALUES    = [0.0001, 0.01, 0.05, 0.1]\n",
    "        self.PREDICT_PROBA_VALUES    = [0.25, 0.50, 0.75]\n",
    "        self.DURATION_VALUES         = [0.1, 1, 29.9, 59.9, 89.9, 119.9, 299]\n",
    "        self.DURATION_PERCENT_VALUES = [0.05, 0.1, 0.2, 0.4]\n",
    "\n",
    "        self.used = 0\n",
    "        self.base_samples = already_used\n",
    "        self.base_i = already_used - 1\n",
    "        self.to_i = already_used\n",
    "\n",
    "        self.class_amount = {}\n",
    "        self.duration_amount = {}\n",
    "\n",
    "        for i in range(len(self.DURATION_VALUES) + 1):\n",
    "            self.duration_amount[i] = 0\n",
    "\n",
    "        for i in range(nclasses):\n",
    "            self.class_amount[i] = 0\n",
    "\n",
    "        self.X_used = np.ndarray(shape = (iters + already_used, cols))\n",
    "        self.y_used = np.ndarray(shape = (iters + already_used,))\n",
    "        self.last_f1 = 0\n",
    "    \n",
    "    def extract_possible_actions(self, state_key):\n",
    "        return list({0, 1})\n",
    "\n",
    "    def select_action(self, state_key, next_action_list):\n",
    "        epsilon_greedy_flag = bool(np.random.binomial(n=1, p=self.epsilon_greedy_rate))\n",
    "\n",
    "        if epsilon_greedy_flag is False:\n",
    "            action_key = random.choice(next_action_list)\n",
    "        else:\n",
    "            action_key = self.predict_next_action(state_key, next_action_list)\n",
    "\n",
    "        return action_key\n",
    "\n",
    "    def train_clf(self, clf):\n",
    "        clf.fit(self.X_used[:self.to_i], \n",
    "                self.y_used[:self.to_i])\n",
    "\n",
    "    def test_acc(self):\n",
    "        self.clf = RandomForestClassifier(max_depth=10, n_jobs=1)\n",
    "\n",
    "        self.train_clf(self.clf)\n",
    "\n",
    "        predict_arr = self.clf.predict(X_test)\n",
    "\n",
    "        return f1_score(y_test, predict_arr, average=\"weighted\")\n",
    "\n",
    "    def observe_reward_value(self, state_key, action_key):\n",
    "        # if action_key == 0:\n",
    "        #     return 0\n",
    "\n",
    "        self.X_used[self.to_i] = X[self.base_i + self.t]\n",
    "        self.y_used[self.to_i] = y[self.base_i + self.t]\n",
    "\n",
    "        self.to_i += 1\n",
    "\n",
    "        cur_f1 = self.test_acc()\n",
    "        reward = cur_f1 - self.last_f1\n",
    "\n",
    "        if action_key == 0:\n",
    "            self.to_i -= 1\n",
    "            reward = -reward\n",
    "        else:\n",
    "            self.last_f1 = cur_f1\n",
    "\n",
    "        self.save_r_df(state_key, reward)\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def learn(self, state_key, limit=1000, increased_rd = 1, decrease_alpha = 0):\n",
    "        self.t = 1\n",
    "\n",
    "        for _ in tqdm(range(1, limit + 1)):\n",
    "            self.epsilon_greedy_rate = min(self.t / increased_rd, 0.9)\n",
    "            self.alpha_value = max(self.alpha_value - decrease_alpha, 0.05)\n",
    "            \n",
    "            next_action_list = self.extract_possible_actions(state_key)\n",
    "            if len(next_action_list):\n",
    "                action_key = self.select_action(\n",
    "                    state_key=state_key,\n",
    "                    next_action_list=next_action_list\n",
    "                )\n",
    "                reward_value = self.observe_reward_value(state_key, action_key)\n",
    "\n",
    "            if len(next_action_list):\n",
    "                # Max-Q-Value in next action time.\n",
    "                next_state_key = self.update_state(\n",
    "                    state_key=state_key,\n",
    "                    action_key=action_key\n",
    "                )\n",
    "\n",
    "                next_next_action_list = self.extract_possible_actions(next_state_key)\n",
    "                next_action_key = self.predict_next_action(next_state_key, next_next_action_list)\n",
    "                next_max_q = self.extract_q_df(next_state_key, next_action_key)\n",
    "\n",
    "                # Update Q-Value.\n",
    "                self.update_q(\n",
    "                    state_key=state_key,\n",
    "                    action_key=action_key,\n",
    "                    reward_value=reward_value,\n",
    "                    next_max_q=next_max_q\n",
    "                )\n",
    "                # Update State.\n",
    "                state_key = next_state_key\n",
    "\n",
    "            # Normalize.\n",
    "            self.normalize_q_value()\n",
    "            self.normalize_r_value()\n",
    "\n",
    "            # Vis.\n",
    "            self.visualize_learning_result(state_key)\n",
    "            # Check.\n",
    "            if self.check_the_end_flag(state_key) is True:\n",
    "                break\n",
    "\n",
    "            # Epsode.\n",
    "            self.t += 1\n",
    "\n",
    "    def save_q_df(self, state_key, action_key, q_value):\n",
    "        '''\n",
    "        Insert or update Q-Value in `self.q_df`.\n",
    "\n",
    "        Args:\n",
    "            state_key:      State.\n",
    "            action_key:     Action.\n",
    "            q_value:        Q-Value.\n",
    "\n",
    "        Exceptions:\n",
    "            TypeError:      If the type of `q_value` is not float.\n",
    "\n",
    "        '''\n",
    "        if isinstance(q_value, float) is False:\n",
    "            raise TypeError(\"The type of q_value must be float.\")\n",
    "\n",
    "        new_q_df = pd.DataFrame([(state_key, action_key, q_value)], columns=[\"state_key\", \"action_key\", \"q_value\"])\n",
    "        \n",
    "        if q_value != 0.0:\n",
    "            self.q_count[(state_key, action_key)] += 1\n",
    "\n",
    "        if self.q_df is not None:\n",
    "            self.q_df = pd.concat([new_q_df, self.q_df])\n",
    "            self.q_df = self.q_df.drop_duplicates([\"state_key\", \"action_key\"])\n",
    "        else:\n",
    "            self.q_df = new_q_df\n",
    "\n",
    "(X_test, y_test) = create_balanced_test_data()\n",
    "\n",
    "increased_rd = 100 # epsilon = min(self.t / increased_rd, 0.9)\n",
    "decrease_alpha = 0.001\n",
    "iters = 100\n",
    "base_samples_amount = 400\n",
    "\n",
    "nclasses = len(train_dataframe.groupby('APP'))\n",
    "\n",
    "q = Q()\n",
    "q.t = 1\n",
    "q.initialize(X.shape[1], iters, base_samples_amount, nclasses)\n",
    "\n",
    "q.X_used[:base_samples_amount] = X[:base_samples_amount]\n",
    "q.y_used[:base_samples_amount] = y[:base_samples_amount]\n",
    "q.last_f1 = q.test_acc()\n",
    "\n",
    "for i in range(base_samples_amount):\n",
    "    q.class_amount[y[i]] += 1\n",
    "\n",
    "state_key = q.update_state(State_key(0, 0, 0, 0, 0), 0)\n",
    "\n",
    "q.learn(state_key, iters, increased_rd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n",
      "q_learning_acc: 0.4223\n",
      "random_learning_acc: 0.4922\n",
      "                                           state_key  action_key   q_value\n",
      "0  State_key(percent_of_class=1, predict_proba=0,...           1  0.010764\n",
      "0  State_key(percent_of_class=1, predict_proba=0,...           1  0.005762\n",
      "0  State_key(percent_of_class=2, predict_proba=1,...           0  0.004267\n",
      "0  State_key(percent_of_class=2, predict_proba=0,...           0  0.003823\n",
      "0  State_key(percent_of_class=2, predict_proba=2,...           0  0.003673\n"
     ]
    }
   ],
   "source": [
    "X_test = test_dataframe.drop(columns=\"APP\").to_numpy()[:100000]\n",
    "y_test = test_dataframe[\"APP\"].to_numpy()[:100000]\n",
    "\n",
    "print(q.to_i)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(q.X_used[:q.to_i], q.y_used[:q.to_i])\n",
    "\n",
    "predict_arr = clf.predict(X_test)\n",
    "\n",
    "print(f\"q_learning_acc: {accuracy_score(y_test, predict_arr):.4f}\")\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X[:1100], y[:1100])\n",
    "\n",
    "predict_arr = clf.predict(X_test)\n",
    "\n",
    "print(f\"random_learning_acc: {accuracy_score(y_test, predict_arr):.4f}\")\n",
    "\n",
    "q_df = q.q_df\n",
    "q_df = q_df.sort_values(by=[\"q_value\"], ascending=False)\n",
    "print(q_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 3)\n",
      "5: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 1, 'q_value': 0.010763502925031287}\n",
      "4: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0057621239816794375}\n",
      "4: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.004267270812079352}\n",
      "4: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.003822623000019569}\n",
      "3: {'state_key': State_key(percent_of_class=2, predict_proba=2, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.0036732236961751243}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=True, percent_duration=0, duration=2), 'action_key': 0, 'q_value': 0.003551871929816386}\n",
      "4: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0029376089477862527}\n",
      "2: {'state_key': State_key(percent_of_class=3, predict_proba=3, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.002850262460146084}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=2, correct_predict=True, percent_duration=0, duration=4), 'action_key': 1, 'q_value': 0.0028218571878269928}\n",
      "2: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.002619618878026165}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=2, correct_predict=True, percent_duration=0, duration=3), 'action_key': 0, 'q_value': 0.0024908971751049225}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=2), 'action_key': 0, 'q_value': 0.002382215063080907}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=3, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.002362612443940454}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0022395901961180134}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=2, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.002032465366281633}\n",
      "1: {'state_key': State_key(percent_of_class=4, predict_proba=2, correct_predict=True, percent_duration=0, duration=2), 'action_key': 0, 'q_value': 0.0020222800021870825}\n",
      "5: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=2), 'action_key': 1, 'q_value': 0.0018880355693868633}\n",
      "1: {'state_key': State_key(percent_of_class=4, predict_proba=2, correct_predict=True, percent_duration=0, duration=6), 'action_key': 0, 'q_value': 0.001840090641289816}\n",
      "1: {'state_key': State_key(percent_of_class=4, predict_proba=2, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0016824807739078366}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=2, correct_predict=True, percent_duration=0, duration=5), 'action_key': 1, 'q_value': 0.001478708554566788}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=False, percent_duration=0, duration=2), 'action_key': 1, 'q_value': 0.001362343164363439}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=3, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0010449712308422399}\n",
      "2: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0010206436954924387}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.0009796321054029889}\n",
      "6: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 1, 'q_value': 0.0008405578629271781}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0005888137840080044}\n",
      "2: {'state_key': State_key(percent_of_class=0, predict_proba=0, correct_predict=False, percent_duration=0, duration=2), 'action_key': 0, 'q_value': 0.0003697588527035423}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0003339490297334158}\n",
      "0: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=4, predict_proba=2, correct_predict=True, percent_duration=0, duration=6), 'action_key': 1, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=2, predict_proba=2, correct_predict=True, percent_duration=0, duration=5), 'action_key': 0, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=4, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=False, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=0, predict_proba=0, correct_predict=False, percent_duration=0, duration=2), 'action_key': 1, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=True, percent_duration=0, duration=0), 'action_key': 1, 'q_value': 0.0}\n",
      "1: {'state_key': State_key(percent_of_class=1, predict_proba=1, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': -0.00010210462425516154}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=2), 'action_key': 0, 'q_value': -0.0001810535648536128}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=2, correct_predict=True, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.00018834406250963778}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=True, percent_duration=0, duration=3), 'action_key': 1, 'q_value': -0.00019819330269787994}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': -0.00023809810052073563}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=3, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': -0.00041105235838363453}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=3, correct_predict=True, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.00045644816362642174}\n",
      "2: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.0004835110466599665}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.0005711410002229412}\n",
      "1: {'state_key': State_key(percent_of_class=0, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.0005802314556206722}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=3, correct_predict=True, percent_duration=0, duration=2), 'action_key': 1, 'q_value': -0.0007199551323763599}\n",
      "2: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.0009182837639096345}\n",
      "2: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=True, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.0010328141223356255}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=True, percent_duration=0, duration=2), 'action_key': 0, 'q_value': -0.0010989899952941196}\n",
      "3: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 0, 'q_value': -0.0013031306036044672}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=2, correct_predict=True, percent_duration=0, duration=4), 'action_key': 0, 'q_value': -0.001505376454926488}\n",
      "1: {'state_key': State_key(percent_of_class=4, predict_proba=2, correct_predict=True, percent_duration=0, duration=2), 'action_key': 1, 'q_value': -0.0020292852860758436}\n",
      "3: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 0, 'q_value': -0.0022067377835946938}\n",
      "1: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 0, 'q_value': -0.0023693244503108614}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=True, percent_duration=0, duration=3), 'action_key': 1, 'q_value': -0.002466984249280424}\n",
      "3: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=False, percent_duration=0, duration=2), 'action_key': 0, 'q_value': -0.0026933756065338588}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=2, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.0027517091442602636}\n",
      "1: {'state_key': State_key(percent_of_class=1, predict_proba=2, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.0027874772281495223}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.002799774250959503}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': -0.0028398649634511167}\n",
      "1: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=False, percent_duration=0, duration=4), 'action_key': 1, 'q_value': -0.0031134712389071523}\n",
      "2: {'state_key': State_key(percent_of_class=0, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.0033982502777739547}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=2), 'action_key': 1, 'q_value': -0.0034452955269117847}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=3), 'action_key': 0, 'q_value': -0.003846512327096684}\n",
      "2: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.004128305038416521}\n"
     ]
    }
   ],
   "source": [
    "print(q_df.shape)\n",
    "\n",
    "for index, row in q_df.iterrows():\n",
    "    count = q.q_count[(row[\"state_key\"], row[\"action_key\"])]\n",
    "    print(f\"{count}: {row.to_dict()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
