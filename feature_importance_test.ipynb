{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8162/8162 [00:08<00:00, 945.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:03<00:00, 48.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1247/1247 [00:08<00:00, 143.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cesnet_datazoo.datasets import CESNET_QUIC22\n",
    "from cesnet_datazoo.config import DatasetConfig, AppSelection, ValidationApproach\n",
    "\n",
    "dataset = CESNET_QUIC22(\"~/datasets/CESNET-QUIC22/\", size=\"XS\")\n",
    "\n",
    "common_params = {\n",
    "    \"dataset\": dataset,\n",
    "    \"apps_selection\": AppSelection.ALL_KNOWN,\n",
    "    \"train_period_name\": \"W-2022-44\",\n",
    "    \"val_approach\": ValidationApproach.SPLIT_FROM_TRAIN,\n",
    "    \"train_val_split_fraction\": 0.2,\n",
    "    \"use_packet_histograms\": True,\n",
    "}\n",
    "dataset_config = DatasetConfig(**common_params)\n",
    "dataset.set_dataset_config_and_initialize(dataset_config)\n",
    "train_dataframe = dataset.get_train_df(flatten_ppi=True)\n",
    "val_dataframe = dataset.get_val_df(flatten_ppi=True)\n",
    "test_dataframe = dataset.get_test_df(flatten_ppi=True)\n",
    "\n",
    "X = train_dataframe.drop(columns=\"APP\").to_numpy()\n",
    "y = train_dataframe[\"APP\"].to_numpy()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs = -1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 0.049026129124047566)\n",
      "(62, 0.039672063141830784)\n",
      "(63, 0.0353087385610517)\n",
      "(64, 0.032289335086405996)\n",
      "(65, 0.027433553591366407)\n",
      "(66, 0.026712175132183318)\n",
      "(90, 0.02334581217729949)\n",
      "(116, 0.022754563632823088)\n",
      "(60, 0.022281908970251178)\n",
      "(110, 0.022151761671259824)\n",
      "(115, 0.021878022165601994)\n",
      "(94, 0.02156386966699109)\n",
      "(61, 0.019202658569022427)\n",
      "(67, 0.01807762321995001)\n",
      "(97, 0.01806561052896565)\n",
      "(108, 0.015640199858541242)\n",
      "(111, 0.015215633153027597)\n",
      "(125, 0.014993252400284358)\n",
      "(1, 0.014563566773058399)\n",
      "(68, 0.014519501322159584)\n",
      "(2, 0.014425318892024556)\n",
      "(72, 0.01379973728739744)\n",
      "(93, 0.01359993157013977)\n",
      "(114, 0.013553933290455986)\n",
      "(70, 0.012937305108541363)\n",
      "(69, 0.012440915981442062)\n",
      "(112, 0.012427787444249227)\n",
      "(73, 0.01183555141871047)\n",
      "(4, 0.011383360606351558)\n",
      "(3, 0.011229132798905625)\n",
      "(71, 0.01093358778794486)\n",
      "(107, 0.010689821781752436)\n",
      "(105, 0.010235159207444633)\n",
      "(113, 0.009867704758064194)\n",
      "(12, 0.009825889266930827)\n",
      "(74, 0.009431361333164216)\n",
      "(104, 0.00937186745800566)\n",
      "(92, 0.009228062397716997)\n",
      "(117, 0.009178282906682168)\n",
      "(13, 0.009130686147503463)\n",
      "(103, 0.00880029627106161)\n",
      "(106, 0.008649547693410036)\n",
      "(5, 0.008070394121462333)\n",
      "(7, 0.007997416429507562)\n",
      "(75, 0.007713131648796842)\n",
      "(6, 0.007654232451244627)\n",
      "(76, 0.0074385698711282346)\n",
      "(31, 0.007372658322512835)\n",
      "(95, 0.007342226717776453)\n",
      "(32, 0.007249015664482461)\n",
      "(8, 0.006959240694766291)\n",
      "(9, 0.006761957628063998)\n",
      "(96, 0.006377620354803461)\n",
      "(33, 0.0061937827801660595)\n",
      "(77, 0.006017962234515735)\n",
      "(37, 0.005992897915525104)\n",
      "(11, 0.0057647812872825424)\n",
      "(14, 0.005620563398130622)\n",
      "(10, 0.005441332350935456)\n",
      "(128, 0.005440017555339947)\n",
      "(78, 0.005389700861769899)\n",
      "(79, 0.004881318047156837)\n",
      "(126, 0.0048530743442778135)\n",
      "(16, 0.004819398945669097)\n",
      "(15, 0.004776903999980257)\n",
      "(127, 0.004676642276047868)\n",
      "(34, 0.0044819658221929995)\n",
      "(80, 0.004318399855446337)\n",
      "(36, 0.004248939679453299)\n",
      "(17, 0.004163816185618771)\n",
      "(81, 0.004141425257685956)\n",
      "(118, 0.003981736254921695)\n",
      "(82, 0.003913455551630027)\n",
      "(83, 0.003477734369288483)\n",
      "(121, 0.003464316063526588)\n",
      "(119, 0.0034077152009094947)\n",
      "(129, 0.003357182792121518)\n",
      "(35, 0.0031650499495329697)\n",
      "(18, 0.003163406687604994)\n",
      "(84, 0.0031620454899078995)\n",
      "(102, 0.003100903903117812)\n",
      "(19, 0.0030632841187440683)\n",
      "(85, 0.0029991887396863637)\n",
      "(20, 0.002705335979945536)\n",
      "(120, 0.002700491835443831)\n",
      "(86, 0.002687280163802617)\n",
      "(38, 0.002618733139579253)\n",
      "(40, 0.002615159536821184)\n",
      "(87, 0.002579654648858125)\n",
      "(21, 0.0025146029919220388)\n",
      "(89, 0.0025129376374903793)\n",
      "(88, 0.002442986200777646)\n",
      "(39, 0.0023765790386746657)\n",
      "(22, 0.0022587462403164237)\n",
      "(124, 0.0022380390690584363)\n",
      "(132, 0.002232911053084659)\n",
      "(42, 0.002132281899920695)\n",
      "(23, 0.002089219791321895)\n",
      "(24, 0.001854221276586283)\n",
      "(41, 0.0018300905552363076)\n",
      "(25, 0.0016855013892639176)\n",
      "(44, 0.0015739156038555968)\n",
      "(47, 0.0015634049210749162)\n",
      "(26, 0.001541748372920153)\n",
      "(43, 0.0015358976088036206)\n",
      "(27, 0.0014855962899352837)\n",
      "(46, 0.0014751777534425664)\n",
      "(45, 0.0014116624876121262)\n",
      "(28, 0.0013893293908437561)\n",
      "(29, 0.0013260899793243958)\n",
      "(48, 0.0011753767976118287)\n",
      "(130, 0.0011718724530998003)\n",
      "(122, 0.0011085587248452467)\n",
      "(52, 0.0010990460191470973)\n",
      "(49, 0.0010586158957027075)\n",
      "(51, 0.0010373562996857147)\n",
      "(50, 0.0009354710037978328)\n",
      "(53, 0.0009290956483247875)\n",
      "(131, 0.0008482963895306685)\n",
      "(123, 0.0008411724834046755)\n",
      "(54, 0.0007858022596467998)\n",
      "(55, 0.0007108500159027606)\n",
      "(57, 0.0006994554041399588)\n",
      "(59, 0.0006837889222751304)\n",
      "(58, 0.0006769398632021917)\n",
      "(56, 0.0006551204378717954)\n",
      "(98, 5.584901064433516e-05)\n",
      "(99, 4.9925500536665366e-05)\n",
      "(100, 1.2856648183510399e-05)\n",
      "(109, 3.2938977774722584e-07)\n",
      "(0, 0.0)\n",
      "(30, 0.0)\n",
      "(101, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fi = clf.feature_importances_\n",
    "fi_arr = []\n",
    "\n",
    "for i, el in enumerate(fi):\n",
    "    fi_arr.append((i, el))\n",
    "\n",
    "fi_arr = sorted(fi_arr, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in fi_arr:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 IPT_1\n",
      "1 IPT_2\n",
      "2 IPT_3\n",
      "3 IPT_4\n",
      "4 IPT_5\n",
      "5 IPT_6\n",
      "6 IPT_7\n",
      "7 IPT_8\n",
      "8 IPT_9\n",
      "9 IPT_10\n",
      "10 IPT_11\n",
      "11 IPT_12\n",
      "12 IPT_13\n",
      "13 IPT_14\n",
      "14 IPT_15\n",
      "15 IPT_16\n",
      "16 IPT_17\n",
      "17 IPT_18\n",
      "18 IPT_19\n",
      "19 IPT_20\n",
      "20 IPT_21\n",
      "21 IPT_22\n",
      "22 IPT_23\n",
      "23 IPT_24\n",
      "24 IPT_25\n",
      "25 IPT_26\n",
      "26 IPT_27\n",
      "27 IPT_28\n",
      "28 IPT_29\n",
      "29 IPT_30\n",
      "30 DIR_1\n",
      "31 DIR_2\n",
      "32 DIR_3\n",
      "33 DIR_4\n",
      "34 DIR_5\n",
      "35 DIR_6\n",
      "36 DIR_7\n",
      "37 DIR_8\n",
      "38 DIR_9\n",
      "39 DIR_10\n",
      "40 DIR_11\n",
      "41 DIR_12\n",
      "42 DIR_13\n",
      "43 DIR_14\n",
      "44 DIR_15\n",
      "45 DIR_16\n",
      "46 DIR_17\n",
      "47 DIR_18\n",
      "48 DIR_19\n",
      "49 DIR_20\n",
      "50 DIR_21\n",
      "51 DIR_22\n",
      "52 DIR_23\n",
      "53 DIR_24\n",
      "54 DIR_25\n",
      "55 DIR_26\n",
      "56 DIR_27\n",
      "57 DIR_28\n",
      "58 DIR_29\n",
      "59 DIR_30\n",
      "60 SIZE_1\n",
      "61 SIZE_2\n",
      "62 SIZE_3\n",
      "63 SIZE_4\n",
      "64 SIZE_5\n",
      "65 SIZE_6\n",
      "66 SIZE_7\n",
      "67 SIZE_8\n",
      "68 SIZE_9\n",
      "69 SIZE_10\n",
      "70 SIZE_11\n",
      "71 SIZE_12\n",
      "72 SIZE_13\n",
      "73 SIZE_14\n",
      "74 SIZE_15\n",
      "75 SIZE_16\n",
      "76 SIZE_17\n",
      "77 SIZE_18\n",
      "78 SIZE_19\n",
      "79 SIZE_20\n",
      "80 SIZE_21\n",
      "81 SIZE_22\n",
      "82 SIZE_23\n",
      "83 SIZE_24\n",
      "84 SIZE_25\n",
      "85 SIZE_26\n",
      "86 SIZE_27\n",
      "87 SIZE_28\n",
      "88 SIZE_29\n",
      "89 SIZE_30\n",
      "90 BYTES\n",
      "91 BYTES_REV\n",
      "92 PACKETS\n",
      "93 PACKETS_REV\n",
      "94 DURATION\n",
      "95 PPI_LEN\n",
      "96 PPI_ROUNDTRIPS\n",
      "97 PPI_DURATION\n",
      "98 FLOW_ENDREASON_IDLE\n",
      "99 FLOW_ENDREASON_ACTIVE\n",
      "100 FLOW_ENDREASON_OTHER\n",
      "101 PSIZE_BIN1\n",
      "102 PSIZE_BIN2\n",
      "103 PSIZE_BIN3\n",
      "104 PSIZE_BIN4\n",
      "105 PSIZE_BIN5\n",
      "106 PSIZE_BIN6\n",
      "107 PSIZE_BIN7\n",
      "108 PSIZE_BIN8\n",
      "109 PSIZE_BIN1_REV\n",
      "110 PSIZE_BIN2_REV\n",
      "111 PSIZE_BIN3_REV\n",
      "112 PSIZE_BIN4_REV\n",
      "113 PSIZE_BIN5_REV\n",
      "114 PSIZE_BIN6_REV\n",
      "115 PSIZE_BIN7_REV\n",
      "116 PSIZE_BIN8_REV\n",
      "117 IPT_BIN1\n",
      "118 IPT_BIN2\n",
      "119 IPT_BIN3\n",
      "120 IPT_BIN4\n",
      "121 IPT_BIN5\n",
      "122 IPT_BIN6\n",
      "123 IPT_BIN7\n",
      "124 IPT_BIN8\n",
      "125 IPT_BIN1_REV\n",
      "126 IPT_BIN2_REV\n",
      "127 IPT_BIN3_REV\n",
      "128 IPT_BIN4_REV\n",
      "129 IPT_BIN5_REV\n",
      "130 IPT_BIN6_REV\n",
      "131 IPT_BIN7_REV\n",
      "132 IPT_BIN8_REV\n",
      "133 APP\n"
     ]
    }
   ],
   "source": [
    "for i, el in enumerate(train_dataframe.columns.tolist()):\n",
    "    print(i, end = \" \")\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1264327, 144476, 96905, 39280, 16213, 5247, 496, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[166569, 964554, 296540, 95292, 33069, 8583, 1467, 452, 237, 106, 75, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "m1 = 0\n",
    "m2 = 0\n",
    "\n",
    "count1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "count2 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "for i in range(len(X)):\n",
    "    count1[np.clip(int(log(X[i][91], 5)) - 4, 1, 7) - 1] += 1\n",
    "    count2[np.clip(int(log(X[i][90], 3)) - 4, 2, 10) - 2] += 1\n",
    "\n",
    "    # if m1 < max(int(log(X[i][91], 5)) - 4, 0):\n",
    "    #     m1 = max(int(log(X[i][91], 5)) - 4, 0)\n",
    "    \n",
    "    # if m2 < max(int(log(X[i][90], 5)) - 4, 0):\n",
    "    #     m2 = max(int(log(X[i][90], 5)) - 4, 0)\n",
    "\n",
    "print(count1)\n",
    "print(count2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
