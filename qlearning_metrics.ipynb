{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8162/8162 [00:08<00:00, 1008.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:03<00:00, 49.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1247/1247 [00:08<00:00, 138.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from cesnet_datazoo.datasets import CESNET_QUIC22\n",
    "from cesnet_datazoo.config import DatasetConfig, AppSelection, ValidationApproach\n",
    "\n",
    "dataset = CESNET_QUIC22(\"~/datasets/CESNET-QUIC22/\", size=\"XS\")\n",
    "\n",
    "common_params = {\n",
    "    \"dataset\": dataset,\n",
    "    \"apps_selection\": AppSelection.ALL_KNOWN,\n",
    "    \"train_period_name\": \"W-2022-44\",\n",
    "    \"val_approach\": ValidationApproach.SPLIT_FROM_TRAIN,\n",
    "    \"train_val_split_fraction\": 0.2,\n",
    "    \"use_packet_histograms\": True,\n",
    "}\n",
    "dataset_config = DatasetConfig(**common_params)\n",
    "dataset.set_dataset_config_and_initialize(dataset_config)\n",
    "train_dataframe = dataset.get_train_df(flatten_ppi=True)\n",
    "val_dataframe = dataset.get_val_df(flatten_ppi=True)\n",
    "test_dataframe = dataset.get_test_df(flatten_ppi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:06<00:16,  4.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 332\u001b[0m\n\u001b[1;32m    328\u001b[0m     q\u001b[38;5;241m.\u001b[39mclass_amount[y[i]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    330\u001b[0m state_key \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mupdate_state(State_key(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 332\u001b[0m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincreased_rd\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 247\u001b[0m, in \u001b[0;36mQ.learn\u001b[0;34m(self, state_key, limit, increased_rd, decrease_alpha)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(next_action_list):\n\u001b[1;32m    243\u001b[0m     action_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_action(\n\u001b[1;32m    244\u001b[0m         state_key\u001b[38;5;241m=\u001b[39mstate_key,\n\u001b[1;32m    245\u001b[0m         next_action_list\u001b[38;5;241m=\u001b[39mnext_action_list\n\u001b[1;32m    246\u001b[0m     )\n\u001b[0;32m--> 247\u001b[0m     reward_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserve_reward_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(next_action_list):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Max-Q-Value in next action time.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     next_state_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_state(\n\u001b[1;32m    252\u001b[0m         state_key\u001b[38;5;241m=\u001b[39mstate_key,\n\u001b[1;32m    253\u001b[0m         action_key\u001b[38;5;241m=\u001b[39maction_key\n\u001b[1;32m    254\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[7], line 221\u001b[0m, in \u001b[0;36mQ.observe_reward_value\u001b[0;34m(self, state_key, action_key)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_used[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_i] \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt]\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 221\u001b[0m cur_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_acc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m reward \u001b[38;5;241m=\u001b[39m cur_f1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_f1\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action_key \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[7], line 206\u001b[0m, in \u001b[0;36mQ.test_acc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_acc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_clf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     predict_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1_score(y_test, predict_arr, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 200\u001b[0m, in \u001b[0;36mQ.train_clf\u001b[0;34m(self, clf)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_clf\u001b[39m(\u001b[38;5;28mself\u001b[39m, clf):\n\u001b[0;32m--> 200\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_used\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_used\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:474\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    463\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    466\u001b[0m ]\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from pyqlearning.q_learning import QLearning\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "X = train_dataframe.drop(columns=\"APP\").to_numpy()\n",
    "y = train_dataframe[\"APP\"].to_numpy()\n",
    "\n",
    "# X_test = test_dataframe.drop(columns=\"APP\").to_numpy()[:10000]\n",
    "# y_test = test_dataframe[\"APP\"].to_numpy()[:10000]\n",
    "\n",
    "# same amount of samples from all classes\n",
    "def create_balanced_test_data():\n",
    "    grouped = test_dataframe.groupby('APP')\n",
    "\n",
    "    X_arr = np.ndarray(shape = (10100, X.shape[1]))\n",
    "    y_arr = np.ndarray(shape = (10100,))\n",
    "\n",
    "    for index, i in enumerate(grouped):\n",
    "        X_temp = i[1].drop(columns=\"APP\").to_numpy()\n",
    "        y_temp = i[1][\"APP\"].to_numpy()\n",
    "\n",
    "        X_arr[index*100:(index*100)+100] = X_temp[:100]\n",
    "        y_arr[index*100:(index*100)+100] = y_temp[:100]\n",
    "\n",
    "    return (X_arr, y_arr)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class State_key:\n",
    "    percent_of_class : int  # 1e-2, 1e-1. 5e-1, 1, more than 1\n",
    "    predict_proba    : int  # 0-25, 25-50, 50-75, 75-100\n",
    "    correct_predict  : bool # True or False\n",
    "    percent_duration : int\n",
    "    # bytes_client     : int  # log3, 9 buckets\n",
    "    # bytes_server     : int  # log5, 7 buckets\n",
    "    duration         : int\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.percent_of_class + \\\n",
    "               self.predict_proba * 5 + \\\n",
    "               int(self.correct_predict) * 20 + \\\n",
    "               self.percent_duration * 40 + \\\n",
    "               self.duration * 320\n",
    "            #    self.bytes_client * 40 + \\\n",
    "            #    self.bytes_server * 360 + \\\n",
    "               \n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, State_key) or self.__hash__() != other.__hash__():\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        # return self.percent_of_class == other.percent_of_class and \\\n",
    "        #        self.predict_proba == other.predict_proba and \\\n",
    "        #        self.percent_used == other.percent_used and \\\n",
    "        #        self.correct_predict == other.correct_predict\n",
    "        \n",
    "class Q(QLearning):\n",
    "    def get_clf_prediction(self, index):\n",
    "\n",
    "        proba = self.clf.predict_proba(X[index].reshape(1, -1))[0]\n",
    "        hit = (self.clf.predict(X[index].reshape(1, -1)) == y[index])[0]\n",
    "\n",
    "        return (proba, hit)\n",
    "\n",
    "    def class_percent_into_discrete(self, percent):\n",
    "        for i in range(len(self.CLASS_PERCENT_VALUES)):\n",
    "            if percent < self.CLASS_PERCENT_VALUES[i]:\n",
    "                return i\n",
    "            \n",
    "        return len(self.CLASS_PERCENT_VALUES)\n",
    "    \n",
    "    def predict_proba_into_discrete(self, proba):\n",
    "        for i in range(len(self.PREDICT_PROBA_VALUES)):\n",
    "            if proba < self.PREDICT_PROBA_VALUES[i]:\n",
    "                return i\n",
    "            \n",
    "        return len(self.PREDICT_PROBA_VALUES)\n",
    "\n",
    "    def percent_used_into_discrete(self, percent):\n",
    "        for i, el in enumerate(self.PERCENT_USED_VALUES):\n",
    "            if percent < el:\n",
    "                return i\n",
    "            \n",
    "        return len(self.PERCENT_USED_VALUES)\n",
    "\n",
    "    def client_bytes_into_discrete(self, nbytes):\n",
    "        return int(np.clip(int(log(nbytes, 3)) - 5, 1, 9) - 1)\n",
    "    \n",
    "    def server_bytes_into_discrete(self, nbytes):\n",
    "        return int(np.clip(int(log(nbytes, 5)) - 4, 0, 7))\n",
    "\n",
    "    def duration_into_discrete(self, duration):\n",
    "        for i, el in enumerate(self.DURATION_VALUES):\n",
    "            if duration < el:\n",
    "                return i\n",
    "        \n",
    "        return len(self.DURATION_VALUES)\n",
    "\n",
    "    def percent_duration_into_discrete(self, duration):\n",
    "        for i, el in enumerate(self.DURATION_PERCENT_VALUES):\n",
    "            if duration < el:\n",
    "                return i\n",
    "        \n",
    "        return len(self.DURATION_PERCENT_VALUES)\n",
    "\n",
    "    def update_state(self, state_key, action_key):\n",
    "        # print(self.t, end = \" \")\n",
    "        # print(state_key, end = \" \")\n",
    "        # print(action_key)\n",
    "\n",
    "        sample_index = self.base_i + self.t + 1\n",
    "\n",
    "        next_class = y[sample_index]\n",
    "\n",
    "        if action_key == 1:\n",
    "            \n",
    "            self.class_amount[self.y_used[self.to_i - 1]] += 1\n",
    "            self.used += 1\n",
    "\n",
    "        class_percent = self.class_amount[next_class] / (self.used + self.base_samples)\n",
    "        \n",
    "        (proba, hit) = self.get_clf_prediction(sample_index)\n",
    "\n",
    "        res_index = np.where(self.clf.classes_ == next_class)\n",
    "        if len(res_index[0]):\n",
    "            proba = self.predict_proba_into_discrete(proba[res_index[0][0]])\n",
    "        else:\n",
    "            proba = 0\n",
    "\n",
    "        # client_bytes = self.client_bytes_into_discrete(X[sample_index][90])\n",
    "        # server_bytes = self.server_bytes_into_discrete(X[sample_index][91])\n",
    "\n",
    "        duration = self.duration_into_discrete(X[sample_index][94])\n",
    "        percent_duration = self.duration_amount[duration] / (self.used + self.base_samples)\n",
    "\n",
    "        return State_key(self.class_percent_into_discrete(class_percent), \n",
    "                         proba,\n",
    "                         hit,\n",
    "                         self.percent_duration_into_discrete(percent_duration),\n",
    "                         duration)\n",
    "\n",
    "    def initialize(self, cols, iters, already_used, nclasses):\n",
    "        self.q_count = defaultdict(int)\n",
    "\n",
    "        self.epsilon_greedy_rate = 0.9\n",
    "        self.alpha_value = 0.4\n",
    "        self.gamma_value = 0.9\n",
    "\n",
    "        self.clf = RandomForestClassifier(max_depth=10)\n",
    "\n",
    "        self.CLASS_PERCENT_VALUES    = [0.0001, 0.01, 0.05, 0.1]\n",
    "        self.PREDICT_PROBA_VALUES    = [0.25, 0.50, 0.75]\n",
    "        self.DURATION_VALUES         = [0.1, 1, 29.9, 59.9, 89.9, 119.9, 299]\n",
    "        self.DURATION_PERCENT_VALUES = [0.05, 0.1, 0.2, 0.4]\n",
    "\n",
    "        self.used = 0\n",
    "        self.base_samples = already_used\n",
    "        self.base_i = already_used - 1\n",
    "        self.to_i = already_used\n",
    "\n",
    "        self.class_amount = {}\n",
    "        self.duration_amount = {}\n",
    "\n",
    "        for i in range(len(self.DURATION_VALUES) + 1):\n",
    "            self.duration_amount[i] = 0\n",
    "\n",
    "        for i in range(nclasses):\n",
    "            self.class_amount[i] = 0\n",
    "\n",
    "        self.X_used = np.ndarray(shape = (iters + already_used, cols))\n",
    "        self.y_used = np.ndarray(shape = (iters + already_used,))\n",
    "        self.last_f1 = 0\n",
    "    \n",
    "    def extract_possible_actions(self, state_key):\n",
    "        return list({0, 1})\n",
    "\n",
    "    def select_action(self, state_key, next_action_list):\n",
    "        epsilon_greedy_flag = bool(np.random.binomial(n=1, p=self.epsilon_greedy_rate))\n",
    "\n",
    "        if epsilon_greedy_flag is False:\n",
    "            action_key = random.choice(next_action_list)\n",
    "        else:\n",
    "            action_key = self.predict_next_action(state_key, next_action_list)\n",
    "\n",
    "        return action_key\n",
    "\n",
    "    def train_clf(self, clf):\n",
    "        clf.fit(self.X_used[:self.to_i], \n",
    "                self.y_used[:self.to_i])\n",
    "\n",
    "    def test_acc(self):\n",
    "        self.clf = RandomForestClassifier(max_depth=10, n_jobs=1)\n",
    "\n",
    "        self.train_clf(self.clf)\n",
    "\n",
    "        predict_arr = self.clf.predict(X_test)\n",
    "\n",
    "        return f1_score(y_test, predict_arr, average=\"weighted\")\n",
    "\n",
    "    def observe_reward_value(self, state_key, action_key):\n",
    "        # if action_key == 0:\n",
    "        #     return 0\n",
    "\n",
    "        self.X_used[self.to_i] = X[self.base_i + self.t]\n",
    "        self.y_used[self.to_i] = y[self.base_i + self.t]\n",
    "\n",
    "        self.to_i += 1\n",
    "\n",
    "        cur_f1 = self.test_acc()\n",
    "        reward = cur_f1 - self.last_f1\n",
    "\n",
    "        if action_key == 0:\n",
    "            self.to_i -= 1\n",
    "            reward = -reward\n",
    "        else:\n",
    "            self.last_f1 = cur_f1\n",
    "\n",
    "        self.save_r_df(state_key, reward)\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def learn(self, state_key, limit=1000, increased_rd = 1, decrease_alpha = 0):\n",
    "        self.t = 1\n",
    "\n",
    "        for _ in tqdm(range(1, limit + 1)):\n",
    "            self.epsilon_greedy_rate = min(self.t / increased_rd, 0.9)\n",
    "            self.alpha_value = max(self.alpha_value - decrease_alpha, 0.05)\n",
    "            \n",
    "            next_action_list = self.extract_possible_actions(state_key)\n",
    "            if len(next_action_list):\n",
    "                action_key = self.select_action(\n",
    "                    state_key=state_key,\n",
    "                    next_action_list=next_action_list\n",
    "                )\n",
    "                reward_value = self.observe_reward_value(state_key, action_key)\n",
    "\n",
    "            if len(next_action_list):\n",
    "                # Max-Q-Value in next action time.\n",
    "                next_state_key = self.update_state(\n",
    "                    state_key=state_key,\n",
    "                    action_key=action_key\n",
    "                )\n",
    "\n",
    "                next_next_action_list = self.extract_possible_actions(next_state_key)\n",
    "                next_action_key = self.predict_next_action(next_state_key, next_next_action_list)\n",
    "                next_max_q = self.extract_q_df(next_state_key, next_action_key)\n",
    "\n",
    "                # Update Q-Value.\n",
    "                self.update_q(\n",
    "                    state_key=state_key,\n",
    "                    action_key=action_key,\n",
    "                    reward_value=reward_value,\n",
    "                    next_max_q=next_max_q\n",
    "                )\n",
    "                # Update State.\n",
    "                state_key = next_state_key\n",
    "\n",
    "            # Normalize.\n",
    "            self.normalize_q_value()\n",
    "            self.normalize_r_value()\n",
    "\n",
    "            # Vis.\n",
    "            self.visualize_learning_result(state_key)\n",
    "            # Check.\n",
    "            if self.check_the_end_flag(state_key) is True:\n",
    "                break\n",
    "\n",
    "            # Epsode.\n",
    "            self.t += 1\n",
    "\n",
    "    def save_q_df(self, state_key, action_key, q_value):\n",
    "        '''\n",
    "        Insert or update Q-Value in `self.q_df`.\n",
    "\n",
    "        Args:\n",
    "            state_key:      State.\n",
    "            action_key:     Action.\n",
    "            q_value:        Q-Value.\n",
    "\n",
    "        Exceptions:\n",
    "            TypeError:      If the type of `q_value` is not float.\n",
    "\n",
    "        '''\n",
    "        if isinstance(q_value, float) is False:\n",
    "            raise TypeError(\"The type of q_value must be float.\")\n",
    "\n",
    "        new_q_df = pd.DataFrame([(state_key, action_key, q_value)], columns=[\"state_key\", \"action_key\", \"q_value\"])\n",
    "        \n",
    "        if q_value != 0.0:\n",
    "            self.q_count[(state_key, action_key)] += 1\n",
    "\n",
    "        if self.q_df is not None:\n",
    "            self.q_df = pd.concat([new_q_df, self.q_df])\n",
    "            self.q_df = self.q_df.drop_duplicates([\"state_key\", \"action_key\"])\n",
    "        else:\n",
    "            self.q_df = new_q_df\n",
    "\n",
    "(X_test, y_test) = create_balanced_test_data()\n",
    "\n",
    "increased_rd = 100 # epsilon = min(self.t / increased_rd, 0.9)\n",
    "decrease_alpha = 0.001\n",
    "iters = 100\n",
    "base_samples_amount = 400\n",
    "\n",
    "nclasses = len(train_dataframe.groupby('APP'))\n",
    "\n",
    "q = Q()\n",
    "q.t = 1\n",
    "q.initialize(X.shape[1], iters, base_samples_amount, nclasses)\n",
    "\n",
    "q.X_used[:base_samples_amount] = X[:base_samples_amount]\n",
    "q.y_used[:base_samples_amount] = y[:base_samples_amount]\n",
    "q.last_f1 = q.test_acc()\n",
    "\n",
    "for i in range(base_samples_amount):\n",
    "    q.class_amount[y[i]] += 1\n",
    "\n",
    "state_key = q.update_state(State_key(0, 0, 0, 0, 0), 0)\n",
    "\n",
    "q.learn(state_key, iters, increased_rd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n",
      "q_learning_acc: 0.4223\n",
      "random_learning_acc: 0.4922\n",
      "                                           state_key  action_key   q_value\n",
      "0  State_key(percent_of_class=1, predict_proba=0,...           1  0.010764\n",
      "0  State_key(percent_of_class=1, predict_proba=0,...           1  0.005762\n",
      "0  State_key(percent_of_class=2, predict_proba=1,...           0  0.004267\n",
      "0  State_key(percent_of_class=2, predict_proba=0,...           0  0.003823\n",
      "0  State_key(percent_of_class=2, predict_proba=2,...           0  0.003673\n"
     ]
    }
   ],
   "source": [
    "X_test = test_dataframe.drop(columns=\"APP\").to_numpy()[:100000]\n",
    "y_test = test_dataframe[\"APP\"].to_numpy()[:100000]\n",
    "\n",
    "print(q.to_i)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(q.X_used[:q.to_i], q.y_used[:q.to_i])\n",
    "\n",
    "predict_arr = clf.predict(X_test)\n",
    "\n",
    "print(f\"q_learning_acc: {accuracy_score(y_test, predict_arr):.4f}\")\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X[:1100], y[:1100])\n",
    "\n",
    "predict_arr = clf.predict(X_test)\n",
    "\n",
    "print(f\"random_learning_acc: {accuracy_score(y_test, predict_arr):.4f}\")\n",
    "\n",
    "q_df = q.q_df\n",
    "q_df = q_df.sort_values(by=[\"q_value\"], ascending=False)\n",
    "print(q_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 3)\n",
      "5: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 1, 'q_value': 0.010763502925031287}\n",
      "4: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0057621239816794375}\n",
      "4: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.004267270812079352}\n",
      "4: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.003822623000019569}\n",
      "3: {'state_key': State_key(percent_of_class=2, predict_proba=2, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.0036732236961751243}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=True, percent_duration=0, duration=2), 'action_key': 0, 'q_value': 0.003551871929816386}\n",
      "4: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0029376089477862527}\n",
      "2: {'state_key': State_key(percent_of_class=3, predict_proba=3, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.002850262460146084}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=2, correct_predict=True, percent_duration=0, duration=4), 'action_key': 1, 'q_value': 0.0028218571878269928}\n",
      "2: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.002619618878026165}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=2, correct_predict=True, percent_duration=0, duration=3), 'action_key': 0, 'q_value': 0.0024908971751049225}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=2), 'action_key': 0, 'q_value': 0.002382215063080907}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=3, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.002362612443940454}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0022395901961180134}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=2, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.002032465366281633}\n",
      "1: {'state_key': State_key(percent_of_class=4, predict_proba=2, correct_predict=True, percent_duration=0, duration=2), 'action_key': 0, 'q_value': 0.0020222800021870825}\n",
      "5: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=2), 'action_key': 1, 'q_value': 0.0018880355693868633}\n",
      "1: {'state_key': State_key(percent_of_class=4, predict_proba=2, correct_predict=True, percent_duration=0, duration=6), 'action_key': 0, 'q_value': 0.001840090641289816}\n",
      "1: {'state_key': State_key(percent_of_class=4, predict_proba=2, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0016824807739078366}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=2, correct_predict=True, percent_duration=0, duration=5), 'action_key': 1, 'q_value': 0.001478708554566788}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=False, percent_duration=0, duration=2), 'action_key': 1, 'q_value': 0.001362343164363439}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=3, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0010449712308422399}\n",
      "2: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0010206436954924387}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.0009796321054029889}\n",
      "6: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 1, 'q_value': 0.0008405578629271781}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0005888137840080044}\n",
      "2: {'state_key': State_key(percent_of_class=0, predict_proba=0, correct_predict=False, percent_duration=0, duration=2), 'action_key': 0, 'q_value': 0.0003697588527035423}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0003339490297334158}\n",
      "0: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=4, predict_proba=2, correct_predict=True, percent_duration=0, duration=6), 'action_key': 1, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=2, predict_proba=2, correct_predict=True, percent_duration=0, duration=5), 'action_key': 0, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=4, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=False, percent_duration=0, duration=1), 'action_key': 0, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=0, predict_proba=0, correct_predict=False, percent_duration=0, duration=2), 'action_key': 1, 'q_value': 0.0}\n",
      "0: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=True, percent_duration=0, duration=0), 'action_key': 1, 'q_value': 0.0}\n",
      "1: {'state_key': State_key(percent_of_class=1, predict_proba=1, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': -0.00010210462425516154}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=2), 'action_key': 0, 'q_value': -0.0001810535648536128}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=2, correct_predict=True, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.00018834406250963778}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=True, percent_duration=0, duration=3), 'action_key': 1, 'q_value': -0.00019819330269787994}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=1, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': -0.00023809810052073563}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=3, correct_predict=True, percent_duration=0, duration=1), 'action_key': 0, 'q_value': -0.00041105235838363453}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=3, correct_predict=True, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.00045644816362642174}\n",
      "2: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.0004835110466599665}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.0005711410002229412}\n",
      "1: {'state_key': State_key(percent_of_class=0, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.0005802314556206722}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=3, correct_predict=True, percent_duration=0, duration=2), 'action_key': 1, 'q_value': -0.0007199551323763599}\n",
      "2: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.0009182837639096345}\n",
      "2: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=True, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.0010328141223356255}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=True, percent_duration=0, duration=2), 'action_key': 0, 'q_value': -0.0010989899952941196}\n",
      "3: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 0, 'q_value': -0.0013031306036044672}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=2, correct_predict=True, percent_duration=0, duration=4), 'action_key': 0, 'q_value': -0.001505376454926488}\n",
      "1: {'state_key': State_key(percent_of_class=4, predict_proba=2, correct_predict=True, percent_duration=0, duration=2), 'action_key': 1, 'q_value': -0.0020292852860758436}\n",
      "3: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 0, 'q_value': -0.0022067377835946938}\n",
      "1: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 0, 'q_value': -0.0023693244503108614}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=True, percent_duration=0, duration=3), 'action_key': 1, 'q_value': -0.002466984249280424}\n",
      "3: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=False, percent_duration=0, duration=2), 'action_key': 0, 'q_value': -0.0026933756065338588}\n",
      "1: {'state_key': State_key(percent_of_class=3, predict_proba=2, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.0027517091442602636}\n",
      "1: {'state_key': State_key(percent_of_class=1, predict_proba=2, correct_predict=True, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.0027874772281495223}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=False, percent_duration=0, duration=0), 'action_key': 1, 'q_value': -0.002799774250959503}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=0, correct_predict=True, percent_duration=0, duration=0), 'action_key': 0, 'q_value': -0.0028398649634511167}\n",
      "1: {'state_key': State_key(percent_of_class=1, predict_proba=0, correct_predict=False, percent_duration=0, duration=4), 'action_key': 1, 'q_value': -0.0031134712389071523}\n",
      "2: {'state_key': State_key(percent_of_class=0, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.0033982502777739547}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=2), 'action_key': 1, 'q_value': -0.0034452955269117847}\n",
      "1: {'state_key': State_key(percent_of_class=2, predict_proba=1, correct_predict=True, percent_duration=0, duration=3), 'action_key': 0, 'q_value': -0.003846512327096684}\n",
      "2: {'state_key': State_key(percent_of_class=3, predict_proba=0, correct_predict=False, percent_duration=0, duration=1), 'action_key': 1, 'q_value': -0.004128305038416521}\n"
     ]
    }
   ],
   "source": [
    "print(q_df.shape)\n",
    "\n",
    "for index, row in q_df.iterrows():\n",
    "    count = q.q_count[(row[\"state_key\"], row[\"action_key\"])]\n",
    "    print(f\"{count}: {row.to_dict()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
