{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/cesnet_datazoo/config.py:341: UserWarning: Some test dates (20221031) are before or equal to the last train date (20221106). This might lead to improper evaluation and should be avoided.\n",
      "  warnings.warn(f\"Some test dates ({min(test_dates).strftime('%Y%m%d')}) are before or equal to the last train date ({max(train_dates).strftime('%Y%m%d')}). This might lead to improper evaluation and should be avoided.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8162/8162 [00:08<00:00, 967.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:04<00:00, 46.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [00:07<00:00, 128.70it/s]\n",
      "  1%|          | 623/100000 [00:20<53:13, 31.12it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 495\u001b[0m\n\u001b[1;32m    493\u001b[0m q\u001b[38;5;241m.\u001b[39minitialize(q\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], iters, base_samples_amount, epsilon, alpha, gamma)\n\u001b[1;32m    494\u001b[0m state_key \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mupdate_state(State_key(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 495\u001b[0m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincreased_rd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecrease_alpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m q\u001b[38;5;241m.\u001b[39msave_table_to_file()\n",
      "Cell \u001b[0;32mIn[6], line 373\u001b[0m, in \u001b[0;36mQ.learn\u001b[0;34m(self, state_key, batch, limit, increased_rd, decrease_alpha)\u001b[0m\n\u001b[1;32m    367\u001b[0m next_action_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_possible_actions(state_key)\n\u001b[1;32m    368\u001b[0m action_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_action(\n\u001b[1;32m    369\u001b[0m     state_key\u001b[38;5;241m=\u001b[39mstate_key,\n\u001b[1;32m    370\u001b[0m     next_action_list\u001b[38;5;241m=\u001b[39mnext_action_list\n\u001b[1;32m    371\u001b[0m )\n\u001b[0;32m--> 373\u001b[0m (proba, hit) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserve_hit_reward\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# seen_states.append([state_key, reward_value])\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# Max-Q-Value in next action time.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m next_state_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_state(\n\u001b[1;32m    378\u001b[0m     state_key\u001b[38;5;241m=\u001b[39mstate_key,\n\u001b[1;32m    379\u001b[0m     action_key\u001b[38;5;241m=\u001b[39maction_key\n\u001b[1;32m    380\u001b[0m )\n",
      "Cell \u001b[0;32mIn[6], line 341\u001b[0m, in \u001b[0;36mQ.observe_hit_reward\u001b[0;34m(self, action_key)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobserve_hit_reward\u001b[39m(\u001b[38;5;28mself\u001b[39m, action_key):\n\u001b[0;32m--> 341\u001b[0m     (proba, hit) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_clf_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     proba_reward \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m-\u001b[39m proba)\n\u001b[1;32m    344\u001b[0m     hit_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hit \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 153\u001b[0m, in \u001b[0;36mQ.get_clf_prediction\u001b[0;34m(self, index, next_class)\u001b[0m\n\u001b[1;32m    150\u001b[0m res_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m==\u001b[39m next_class)\n\u001b[1;32m    152\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[index]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 153\u001b[0m hit \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[index])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res_index[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    156\u001b[0m     proba \u001b[38;5;241m=\u001b[39m proba[res_index[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:821\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    801\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 821\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    824\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:874\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    869\u001b[0m all_proba \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    870\u001b[0m     np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], j), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[1;32m    872\u001b[0m ]\n\u001b[1;32m    873\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[0;32m--> 874\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[1;32m    880\u001b[0m     proba \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from pyqlearning.q_learning import QLearning\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocess as mp\n",
    "\n",
    "from datetime import datetime\n",
    "with open(\"out.txt\", \"a\") as f:\n",
    "    time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    f.write(\"\\nstart(\" + time + \")\")\n",
    "\n",
    "def create_balanced_test_data(nfeatures, nfrom_class = 100):\n",
    "    grouped = test_dataframe.groupby('APP')\n",
    "\n",
    "    X_arr = np.ndarray(shape = (nfrom_class * len(grouped), nfeatures))\n",
    "    y_arr = np.ndarray(shape = (nfrom_class * len(grouped),))\n",
    "\n",
    "    for index, i in enumerate(grouped):\n",
    "        X_temp = i[1].drop(columns=\"APP\").to_numpy()\n",
    "        y_temp = i[1][\"APP\"].to_numpy()\n",
    "\n",
    "        X_arr[index*nfrom_class:(index * nfrom_class) + nfrom_class] = X_temp[:nfrom_class]\n",
    "        y_arr[index*nfrom_class:(index * nfrom_class) + nfrom_class] = y_temp[:nfrom_class]\n",
    "\n",
    "    return (X_arr, y_arr)\n",
    "\n",
    "def topx_indexes(dataframe, nclasses):\n",
    "    grouped_counts = dataframe.groupby(\"APP\").size()\n",
    "    grouped_counts = grouped_counts.sort_values(ascending=False)\n",
    "\n",
    "    topx_groups = grouped_counts.head(nclasses).index\n",
    "\n",
    "    return topx_groups\n",
    "\n",
    "def QUIC_dataset(nclasses = 0):\n",
    "    from cesnet_datazoo.datasets import CESNET_QUIC22\n",
    "    from cesnet_datazoo.config import DatasetConfig, AppSelection, ValidationApproach\n",
    "\n",
    "    dataset = CESNET_QUIC22(\"~/datasets/CESNET-QUIC22/\", size=\"XS\")\n",
    "\n",
    "    common_params = {\n",
    "        \"dataset\" : dataset,\n",
    "        \"apps_selection\" : AppSelection.ALL_KNOWN,\n",
    "        \"test_period_name\" : \"W-2022-44\",\n",
    "        \"val_approach\": ValidationApproach.SPLIT_FROM_TRAIN,\n",
    "        \"train_val_split_fraction\": 0.2\n",
    "    }\n",
    "\n",
    "    dataset_config = DatasetConfig(**common_params)\n",
    "    dataset.set_dataset_config_and_initialize(dataset_config)\n",
    "    train_dataframe = dataset.get_train_df(flatten_ppi=True)\n",
    "    val_dataframe = dataset.get_val_df(flatten_ppi=True)\n",
    "    test_dataframe = dataset.get_test_df(flatten_ppi=True)\n",
    "\n",
    "    if nclasses != 0:\n",
    "        topx_groups = topx_indexes(train_dataframe, nclasses)\n",
    "\n",
    "        train_dataframe = train_dataframe[train_dataframe[\"APP\"].isin(topx_groups)]\n",
    "        test_dataframe  = test_dataframe[test_dataframe[\"APP\"].isin(topx_groups)]\n",
    "        val_dataframe   = val_dataframe[val_dataframe[\"APP\"].isin(topx_groups)]\n",
    "\n",
    "    return (train_dataframe, val_dataframe, test_dataframe)\n",
    "\n",
    "@dataclass\n",
    "class State_key:\n",
    "    percent_of_class     : int  # 1e-2, 1e-1. 5e-1, 1, more than 1\n",
    "    # predict_proba    : int  # 0-25, 25-50, 50-75, 75-100\n",
    "    # correct_predict  : bool # True or False\n",
    "    duration             : int  # 8 buckets\n",
    "    percent_duration     : int  # 5 buckets\n",
    "    bytes_client         : int  # log3, 9 buckets\n",
    "    bytes_server         : int  # log5, 7 buckets\n",
    "    ppi_duration         : int  # 6\n",
    "    ppi_percent_duration : int  # 5\n",
    "    centroid_size        : int  # 4\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.percent_of_class + \\\n",
    "               self.duration * 5 + \\\n",
    "               self.percent_duration * 40 + \\\n",
    "               self.bytes_client * 200 + \\\n",
    "               self.bytes_server * 1800 + \\\n",
    "               self.ppi_duration * 12600 + \\\n",
    "               self.ppi_percent_duration * 75600 + \\\n",
    "               self.centroid_size * 378800\n",
    "               # self.predict_proba * 5 + \\\n",
    "               # int(self.correct_predict) * 20 + \\\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, State_key) or self.__hash__() != other.__hash__():\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "        # return self.percent_of_class == other.percent_of_class and \\\n",
    "        #        self.predict_proba == other.predict_proba and \\\n",
    "        #        self.percent_used == other.percent_used and \\\n",
    "        #        self.correct_predict == other.correct_predict\n",
    "        \n",
    "class Q(QLearning):\n",
    "    def big_test(self):\n",
    "        with open(\"out.txt\", \"a\") as f:\n",
    "            f.write(str(self.to_i) + \"\\n\")\n",
    "            \n",
    "            clf = RandomForestClassifier(max_depth=self.m_depth, n_jobs=-1)\n",
    "            clf.fit(self.X_used[:self.to_i], self.y_used[:self.to_i])\n",
    "            \n",
    "            predict_arr = clf.predict(self.X_big_test)\n",
    "            \n",
    "            f.write(f\"q_learning_acc: {accuracy_score(self.y_big_test, predict_arr):.4f}\" + \"\\n\")\n",
    "            \n",
    "\n",
    "            val = 0\n",
    "            for i in range(3):\n",
    "                clf = RandomForestClassifier(max_depth=self.m_depth, n_jobs=-1)\n",
    "                indices = np.random.choice(self.base_samples + self.t, self.to_i, replace=False)\n",
    "        \n",
    "                clf.fit(self.X[indices], self.y[indices])\n",
    "                \n",
    "                predict_arr = clf.predict(self.X_big_test)\n",
    "\n",
    "                val += accuracy_score(self.y_big_test, predict_arr)\n",
    "\n",
    "            val /= 3\n",
    "            f.write(f\"random_learning_acc: {val:.4f}\" + \"\\n\")\n",
    "            \n",
    "            clf = RandomForestClassifier(max_depth=self.m_depth, n_jobs=-1)\n",
    "            clf.fit(self.X[:self.base_samples + self.t], self.y[:self.base_samples + self.t])\n",
    "            \n",
    "            predict_arr = clf.predict(self.X_big_test)\n",
    "            \n",
    "            f.write(f\"total_learning_acc: {accuracy_score(self.y_big_test, predict_arr):.4f}\" + \"\\n\")\n",
    "            \n",
    "            q_df = self.q_df\n",
    "            q_df = q_df.sort_values(by=[\"q_value\"], ascending=False)\n",
    "            f.write(str(q_df.head()) + \"\\n\\n\")\n",
    "\n",
    "    def get_clf_prediction(self, index, next_class):\n",
    "\n",
    "        res_index = np.where(self.clf.classes_ == next_class)\n",
    "        \n",
    "        proba = self.clf.predict_proba(self.X[index].reshape(1, -1))[0]\n",
    "        hit = (self.clf.predict(self.X[index].reshape(1, -1)) == self.y[index])[0]\n",
    "\n",
    "        if len(res_index[0]):\n",
    "            proba = proba[res_index[0][0]]\n",
    "        else:\n",
    "            proba = 0\n",
    "        \n",
    "        return (proba, hit)\n",
    "    \n",
    "    def value_into_discrete(self, value, thresholds):\n",
    "        for i, threshold in enumerate(thresholds):\n",
    "            if value < threshold:\n",
    "                return i\n",
    "        return len(thresholds)\n",
    "\n",
    "    def class_percent_into_discrete(self, percent):\n",
    "        return self.value_into_discrete(percent, self.CLASS_PERCENT_VALUES)\n",
    "\n",
    "    def predict_proba_into_discrete(self, proba):\n",
    "        return self.value_into_discrete(proba, self.PREDICT_PROBA_VALUES)\n",
    "\n",
    "    def percent_used_into_discrete(self, percent):\n",
    "        return self.value_into_discrete(percent, self.PERCENT_USED_VALUES)\n",
    "    \n",
    "    def duration_into_discrete(self, duration):\n",
    "        return self.value_into_discrete(duration, self.DURATION_VALUES)\n",
    "\n",
    "    def percent_duration_into_discrete(self, duration_percent):\n",
    "        return self.value_into_discrete(duration_percent, self.DURATION_PERCENT_VALUES)\n",
    "    \n",
    "    def ppi_duration_into_discrete(self, duration):\n",
    "        return self.value_into_discrete(duration, self.PPI_DURATION_VALUES)\n",
    "    \n",
    "    def ppi_percent_duration_into_discrete(self, duration_percent):\n",
    "        return self.value_into_discrete(duration_percent, self.PPI_DURATION_PERCENT_VALUES)\n",
    "            \n",
    "    def centroid_size_into_discrete(self, size):\n",
    "        return self.value_into_discrete(size, self.CENTROID_SIZE_VALUES)\n",
    "\n",
    "    def client_bytes_into_discrete(self, nbytes):\n",
    "        return int(np.clip(int(log(nbytes, 3)) - 5, 1, 9) - 1)\n",
    "    \n",
    "    def server_bytes_into_discrete(self, nbytes):\n",
    "        return int(np.clip(int(log(nbytes, 5)) - 4, 0, 7))\n",
    "    \n",
    "    def calculate_distance(self, sum, value, n):\n",
    "        if n == 0:\n",
    "            return value\n",
    "\n",
    "        avg = sum / n\n",
    "\n",
    "        return abs(avg - value)\n",
    "\n",
    "    def calculate_centroid_size(self, cl, values):\n",
    "        sum = 0\n",
    "        for i in range(self.num_of_sizes):\n",
    "            sum += self.calculate_distance(self.class_size_sums[cl][i], values[i + 60], self.to_i)\n",
    "\n",
    "        return sum / self.num_of_sizes\n",
    "\n",
    "    def update_state(self, state_key, action_key):\n",
    "        sample_index = self.base_i + self.t + 1\n",
    "\n",
    "        next_class = self.y[sample_index]\n",
    "        \n",
    "        if action_key == 1:\n",
    "            prev_duration = self.duration_into_discrete(self.X_used[self.to_i - 1][94])\n",
    "            prev_ppi_duration = self.ppi_duration_into_discrete(self.X_used[self.to_i - 1][97])\n",
    "            prev_class = self.y_used[self.to_i - 1]\n",
    "\n",
    "            for i in range(self.num_of_sizes):\n",
    "                self.class_size_sums[prev_class][i] = self.X_used[self.to_i - 1][i + 60]\n",
    "\n",
    "            self.duration_amount[prev_duration] += 1\n",
    "            self.ppi_duration_amount[prev_ppi_duration] += 1\n",
    "            self.class_amount[prev_class] += 1\n",
    "            self.used += 1\n",
    "\n",
    "        class_percent = self.class_amount[next_class] / (self.used + self.base_samples)\n",
    "\n",
    "        client_bytes = self.client_bytes_into_discrete(self.X[sample_index][90])\n",
    "        server_bytes = self.server_bytes_into_discrete(self.X[sample_index][91])\n",
    "\n",
    "        duration = self.duration_into_discrete(self.X[sample_index][94])\n",
    "        percent_duration = self.duration_amount[duration] / (self.used + self.base_samples)\n",
    "\n",
    "        ppi_duration = self.ppi_duration_into_discrete(self.X[sample_index][97])\n",
    "        ppi_percent_duration = self.ppi_duration_amount[ppi_duration] / (self.used + self.base_samples)\n",
    "\n",
    "        centroid_size = self.calculate_centroid_size(next_class, self.X[sample_index])\n",
    "\n",
    "        return State_key(self.class_percent_into_discrete(class_percent), \n",
    "                         duration,\n",
    "                         self.percent_duration_into_discrete(percent_duration),\n",
    "                         client_bytes,\n",
    "                         server_bytes,\n",
    "                         ppi_duration,\n",
    "                         self.ppi_percent_duration_into_discrete(ppi_percent_duration),\n",
    "                         self.centroid_size_into_discrete(centroid_size))\n",
    "\n",
    "    def initialize(self, cols, iters, already_used, nclasses, epsilon = 0.9, alpha = 0.2, gamma = 0.9):\n",
    "        self.q_count = defaultdict(int)\n",
    "\n",
    "        self.epsilon_greedy_rate = epsilon\n",
    "        self.alpha_value         = alpha\n",
    "        self.gamma_value         = gamma\n",
    "\n",
    "        self.m_depth = 15\n",
    "\n",
    "        self.CLASS_PERCENT_VALUES        = [0.01, 0.05, 0.1, 0.2]\n",
    "        self.PREDICT_PROBA_VALUES        = [0.25, 0.50, 0.75]\n",
    "        self.DURATION_VALUES             = [0.1, 1, 29.9, 59.9, 89.9, 119.9, 299]\n",
    "        self.DURATION_PERCENT_VALUES     = [0.05, 0.1, 0.2, 0.4]\n",
    "        self.PPI_DURATION_VALUES         = [0.2, 9.9, 19.9, 70, 112]\n",
    "        self.PPI_DURATION_PERCENT_VALUES = [0.005, 0.01, 0.1, 0.4]\n",
    "        self.CENTROID_SIZE_VALUES        = [300, 500, 800]\n",
    "\n",
    "        self.used         = 0\n",
    "        self.base_samples = already_used\n",
    "        self.base_i       = already_used - 1\n",
    "        self.to_i         = already_used\n",
    "\n",
    "        self.class_amount        = defaultdict(int)\n",
    "        self.duration_amount     = defaultdict(int)\n",
    "        self.ppi_duration_amount = defaultdict(int)\n",
    "\n",
    "        self.X_used = np.ndarray(shape = (iters + already_used, cols))\n",
    "        self.y_used = np.ndarray(shape = (iters + already_used,))\n",
    "        self.last_f1 = 0\n",
    "\n",
    "        ## add base samples to state and learn the first iter of classifier\n",
    "        self.X_used[:self.base_samples] = self.X[:self.base_samples]\n",
    "        self.y_used[:self.base_samples] = self.y[:self.base_samples]\n",
    "\n",
    "        self.clf = RandomForestClassifier(max_depth=self.m_depth, n_jobs=-1)\n",
    "        self.last_f1 = self.test_acc()\n",
    "        \n",
    "        self.num_of_sizes = 12\n",
    "\n",
    "        self.class_size_sums = {}\n",
    "        for class_i in range(200):\n",
    "            self.class_size_sums[class_i] = []\n",
    "            for _ in range(self.num_of_sizes):\n",
    "                self.class_size_sums[class_i].append(0)\n",
    "\n",
    "        for i in range(self.base_samples):\n",
    "            self.class_amount[self.y[i]] += 1\n",
    "            self.duration_amount[self.duration_into_discrete(self.X[i][94])] += 1\n",
    "            self.used += 1\n",
    "\n",
    "    def extract_possible_actions(self, state_key):\n",
    "        return list({0, 1})\n",
    "\n",
    "    def select_action(self, state_key, next_action_list):\n",
    "        epsilon_greedy_flag = bool(np.random.binomial(n=1, p=self.epsilon_greedy_rate))\n",
    "\n",
    "        if epsilon_greedy_flag is False:\n",
    "            action_key = random.choice(next_action_list)\n",
    "        else:\n",
    "            action_key = self.predict_next_action(state_key, next_action_list)\n",
    "\n",
    "        return action_key\n",
    "\n",
    "    def train_clf(self, clf):\n",
    "        clf.fit(self.X_used[:self.to_i], \n",
    "                self.y_used[:self.to_i])\n",
    "\n",
    "    def test_acc(self):\n",
    "        self.clf = RandomForestClassifier(max_depth=self.m_depth, n_jobs=-1, random_state=10)\n",
    "\n",
    "        self.train_clf(self.clf)\n",
    "\n",
    "        predict_arr = self.clf.predict(self.X_test)\n",
    "\n",
    "        return f1_score(self.y_test, predict_arr, average=\"weighted\")\n",
    "\n",
    "    def observe_reward_value(self, state_key, action_key):\n",
    "        pass\n",
    "\n",
    "    def observe_acc_reward(self, action_key):\n",
    "        cur_f1 = self.test_acc()\n",
    "        reward = cur_f1 - self.last_f1\n",
    "\n",
    "        self.last_f1 = cur_f1\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def observe_hit_reward(self, action_key):\n",
    "        (proba, hit) = self.get_clf_prediction(self.base_i + self.t, self.y[self.base_i + self.t])\n",
    "\n",
    "        proba_reward = (0.5 - proba)\n",
    "        hit_reward = -1 if hit == 1 else 1\n",
    "\n",
    "        if action_key == 1:\n",
    "            self.X_used[self.to_i] = self.X[self.base_i + self.t]\n",
    "            self.y_used[self.to_i] = self.y[self.base_i + self.t]\n",
    "            self.to_i += 1\n",
    "\n",
    "        return (proba_reward, hit_reward)\n",
    "\n",
    "    def learn(self, state_key, batch = 1, limit=1000, increased_rd = 1, decrease_alpha = 0):\n",
    "        self.t = 1\n",
    "        last_t = 1\n",
    "\n",
    "        seen_states = []\n",
    "\n",
    "        for _ in tqdm(range(1, limit + 1)):\n",
    "            if self.t - last_t > 4999:\n",
    "                self.big_test()\n",
    "                last_t = self.t\n",
    "\n",
    "            self.epsilon_greedy_rate = min(self.t / increased_rd, 0.9)\n",
    "            self.alpha_value = max(self.alpha_value - decrease_alpha, 0.05)\n",
    "            \n",
    "            next_action_list = self.extract_possible_actions(state_key)\n",
    "            action_key = self.select_action(\n",
    "                state_key=state_key,\n",
    "                next_action_list=next_action_list\n",
    "            )\n",
    "\n",
    "            (proba, hit) = self.observe_hit_reward(action_key)\n",
    "            # seen_states.append([state_key, reward_value])\n",
    "\n",
    "            # Max-Q-Value in next action time.\n",
    "            next_state_key = self.update_state(\n",
    "                state_key=state_key,\n",
    "                action_key=action_key\n",
    "            )\n",
    "\n",
    "            next_next_action_list = self.extract_possible_actions(next_state_key)\n",
    "            next_action_key = self.predict_next_action(next_state_key, next_next_action_list)\n",
    "            next_max_q = self.extract_q_df(next_state_key, next_action_key)\n",
    "\n",
    "            seen_states.append([state_key, action_key, proba, hit, next_max_q])\n",
    "\n",
    "            if self.t % batch == 1:\n",
    "                reward = self.observe_acc_reward(action_key)\n",
    "\n",
    "                for el in seen_states:\n",
    "                    (state_key, action_key, proba, hit, next_max_q) = el\n",
    "\n",
    "                    # Tried with values of 0.98 0.01  0.01\n",
    "                    #                      0.5  0.3   0.2\n",
    "                    #                      0.7  0.2   0.1\n",
    "                    #                      0.9  0.05  0.05\n",
    "                    #                      0.95 0.025 0.025\n",
    "                    #\n",
    "                    # This one worked best 0.97 0.015 0.015\n",
    "                    # For a subset of 10 classes 0.97 0.015 0.005\n",
    "                    reward_value = (0.97 * reward + 0.015 * proba + 0.01 * hit)\n",
    "\n",
    "                    if action_key == 0:\n",
    "                        reward_value = -reward_value\n",
    "\n",
    "                    self.update_q(\n",
    "                        state_key=state_key,\n",
    "                        action_key=action_key,\n",
    "                        reward_value=reward_value,\n",
    "                        next_max_q=next_max_q\n",
    "                    )\n",
    "\n",
    "                    self.save_r_df(state_key, reward_value)\n",
    "\n",
    "                seen_states = []\n",
    "\n",
    "            # Update State.\n",
    "            state_key = next_state_key\n",
    "\n",
    "            # Normalize.\n",
    "            self.normalize_q_value()\n",
    "            self.normalize_r_value()\n",
    "\n",
    "            # # Vis.\n",
    "            # self.visualize_learning_result(state_key)\n",
    "            # # Check.\n",
    "            # if self.check_the_end_flag(state_key) is True:\n",
    "            #     break\n",
    "\n",
    "            self.t += 1\n",
    "\n",
    "    def save_q_df(self, state_key, action_key, q_value):\n",
    "        if isinstance(q_value, float) is False:\n",
    "            raise TypeError(\"The type of q_value must be float.\")\n",
    "\n",
    "        new_q_df = pd.DataFrame([(state_key, action_key, q_value)], columns=[\"state_key\", \"action_key\", \"q_value\"])\n",
    "        \n",
    "        if q_value != 0.0:\n",
    "            self.q_count[(state_key, action_key)] += 1\n",
    "\n",
    "        if self.q_df is not None:\n",
    "            self.q_df = pd.concat([new_q_df, self.q_df])\n",
    "            self.q_df = self.q_df.drop_duplicates([\"state_key\", \"action_key\"])\n",
    "        else:\n",
    "            self.q_df = new_q_df\n",
    "\n",
    "    def export_table(self):\n",
    "        return (self.q_df, self.r_df)\n",
    "    \n",
    "    def save_table_to_file(self, path = \"out_state.txt\"):\n",
    "        with open(path, \"w\") as f:\n",
    "            f.write(\"qvalues\\n---------------\\n\")\n",
    "            for index, row in self.q_df.iterrows():\n",
    "                for el in row:\n",
    "                    f.write(str(el) + \" \")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "            f.write(\"rewards\\n---------------\\n\")\n",
    "            for index, row in self.r_df.iterrows():\n",
    "                for el in row:\n",
    "                    f.write(str(el) + \" \")\n",
    "                f.write(\"\\n\")\n",
    "    \n",
    "    def import_table(self, q_df, r_df):\n",
    "        self.q_df = q_df\n",
    "        self.r_df = r_df\n",
    "    \n",
    "increased_rd = 500 # epsilon = min(self.t / increased_rd, 0.9)\n",
    "decrease_alpha = 0.0001\n",
    "iters = 100000\n",
    "base_samples_amount = 400\n",
    "epsilon = 0.9\n",
    "alpha = 0.2\n",
    "gamma = 0.95\n",
    "\n",
    "# nclasses = len(train_dataframe.groupby('APP'))\n",
    "nclasses = 10\n",
    "\n",
    "(train_dataframe, val_dataframe, test_dataframe) = QUIC_dataset(nclasses)\n",
    "\n",
    "q = Q()\n",
    "q.t = 1\n",
    "\n",
    "q.X = train_dataframe.drop(columns=\"APP\").to_numpy()\n",
    "q.y = train_dataframe[\"APP\"].to_numpy()\n",
    "\n",
    "(q.X_test, q.y_test) = create_balanced_test_data(q.X.shape[1], 1000)\n",
    "\n",
    "q.X_big_test = test_dataframe.drop(columns=\"APP\").to_numpy()[:100000]\n",
    "q.y_big_test = test_dataframe[\"APP\"].to_numpy()[:100000]\n",
    "\n",
    "q.initialize(q.X.shape[1], iters, base_samples_amount, epsilon, alpha, gamma)\n",
    "state_key = q.update_state(State_key(0, 0, 0, 0, 0, 0, 0, 0), 0)\n",
    "q.learn(state_key, 100, iters, increased_rd, decrease_alpha)\n",
    "\n",
    "\n",
    "q.save_table_to_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
